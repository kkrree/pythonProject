{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Sepal.Length', 'Sepal.Width', 'Petal.Length', 'Petal.Width',\n",
       "       'Species'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#로지스틱 회귀 모형의 penalty\n",
    "import pandas as pd\n",
    "df = pd.read_csv('/Users/soojungchoi/pythonProject/pythonBasic/data/iris.csv')\n",
    "df= df.drop(columns=['Unnamed: 0'], axis=1)\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/envs/virt/lib/python3.7/site-packages/pandas/core/indexing.py:1732: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_block(indexer, value, name)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    50\n",
       "1    50\n",
       "2    50\n",
       "Name: Result, dtype: int64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.insert(5,'Result',0)\n",
    "\n",
    "for i in range(len(df)):\n",
    "    species = df['Species'].iloc[i]\n",
    "    result = df['Result'].iloc[i]\n",
    "    result = 0 if species=='setosa' else 1 if species=='versicolor' else 2\n",
    "    df['Result'].iloc[i] = result\n",
    "df.Result.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols=['Sepal.Length', 'Sepal.Width', 'Petal.Length', 'Petal.Width']\n",
    "X=df[cols]\n",
    "y=df['Result']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    40\n",
       "1    40\n",
       "2    40\n",
       "Name: Result, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2,stratify=y,random_state=0)\n",
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#회귀계수들이 학습용 데이터에 과적합이 되지 않도록 정규화 요소를 더해주는 기법\n",
    "#과적합이 발생할 수 있는 수치에 Penalty룰 부여하는 방식\n",
    "#l1,l2,(L1,L2)elasticnet,none \n",
    "\n",
    "#l1 : 오차의 절대값에 페널티를 부여\n",
    "#LASSO(Least Absolute Shrinkage Selector Operator Penalty)\n",
    "#변수들이 많을 경우 실질적으로 영향을 미치는 변수의 갯수는 적을 것이라는 가정\n",
    "#영향이 적은 변수들을 0으로 보내서 없애고 영향력이 큰 변수들만 선택\n",
    "#모형을 단순화시켜 해석이 용이함\n",
    "\n",
    "#l2 : 오차를 제곱한 값에 페널티를 부여(일반적으로 사용하는 방식)\n",
    "#Ridge Penalty\n",
    "#변수들 간의 공선성 구조가 있을 때 사용\n",
    "#공선성이 있을 경우 변수는 많지만 실제 사용가능한 정보는 적음\n",
    "#변수들간의 분산을 감소시키는 기능\n",
    "\n",
    "#elasticnet : LASSO와 Ridge의 혼합형\n",
    "#변수도 줄이고 분산도 줄이고 싶은 경우에 사용\n",
    "\n",
    "#none : penalty를 사용하지 않음\n",
    "\n",
    "#solver : 최적화(최적의 가중치를 설정)에 사용할 알고리즘(newton-cg, lbfgs, liblinear, sag, sgag)\n",
    "#lbfgs(Limited Memory Broyden-Fletcher-Goldfard-Shanno) : 기본값\n",
    "#liblinear : small dataset에 적합\n",
    "#sag(Stochastic Anerage Gradient descent), saga(Variant of Sag) : big dataset에 적합\n",
    "#newton-cg, saga, lbfgs : multi class 지원"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "models = [\n",
    "    LogisticRegression(random_state=0, penalty='l1',solver='liblinear'),\n",
    "    LogisticRegression(random_state=0, penalty='l2'), #기본값\n",
    "    LogisticRegression(random_state=0, penalty='elasticnet', solver='saga', l1_ratio=1, max_iter=1000),\n",
    "    LogisticRegression(random_state=0, penalty='none')\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(penalty='l1', random_state=0, solver='liblinear')\n",
      "학습용: 0.9583333333333334\n",
      "검증용: 0.9666666666666667\n",
      "\n",
      "LogisticRegression(random_state=0)\n",
      "학습용: 0.9666666666666667\n",
      "검증용: 1.0\n",
      "\n",
      "LogisticRegression(l1_ratio=1, max_iter=1000, penalty='elasticnet',\n",
      "                   random_state=0, solver='saga')\n",
      "학습용: 0.975\n",
      "검증용: 1.0\n",
      "\n",
      "LogisticRegression(penalty='none', random_state=0)\n",
      "학습용: 0.9833333333333333\n",
      "검증용: 1.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/envs/virt/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/opt/homebrew/anaconda3/envs/virt/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n"
     ]
    }
   ],
   "source": [
    "for logit in models:\n",
    "    print(logit)\n",
    "    logit.fit(X_train,y_train)\n",
    "    \n",
    "    print('학습용:',logit.score(X_train,y_train))\n",
    "    print('검증용:',logit.score(X_test,y_test))\n",
    "    \n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "053d2992ea4a1306d75dbbbe749afeb63994e3a3213349c301f382405d7edb98"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 ('virt')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
